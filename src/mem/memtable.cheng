module pebble_mem_memtable

import "../core/types.cheng" as core_types
import "../mem/types.cheng" as mem_types
import "../runtime/executor.cheng" as exec
import "../runtime/resource_manager.cheng" as resource
import cheng / stdlib / bootstrap / core / option as option

const
    EntryOverhead = 16

fn defaultComparator(): core_types.Comparator =
    return core_types.CompareBytewise

fn InitMemTable(cfg: mem_types.MemTableConfig): mem_types.MemTable =
    var table: mem_types.MemTable = new[mem_types.MemTable]()
    if table == nil:
        return table
    var normalized = cfg
    mem_types.Normalize(normalized.throttleConfig)
    table.cfg = normalized
    table.base = new[mem_types.Flushable]()
    if table.base != nil:
        table.base.comparator = if table.cfg.comparator != nil: table.cfg.comparator else: defaultComparator()
        table.base.approxBytes = 0
        table.base.frozen = false
    table.records = @[]
    table.bytesUsed = 0
    table.lastSeq = core_types.ToSequence(0)
    table.tickets = @[]
    table.flushScheduled = false
    table.throttleActive = false
    table.lastThrottleDelayMs = 0
    return table

fn verifySequence(mt: mem_types.MemTable, seq: core_types.SequenceNumber) =
    if core_types.ToUint64(seq) < core_types.ToUint64(mt.lastSeq):
        raise newException(mem_types.MemError, "sequence numbers must be monotonically increasing")

fn triggerFlush(mt: mem_types.MemTable) =
    if mt.cfg.flushTrigger == nil:
        return
    if mt.flushScheduled:
        return
    mt.flushScheduled = true
    let trigger = mt.cfg.flushTrigger
    let target = mt.base
    if mt.cfg.flushExecutor == nil:
        trigger(target)
    else:
        discard exec.Submit(mt.cfg.flushExecutor, fn () =
            trigger(target)
        )

fn markFrozenForFlush(mt: mem_types.MemTable) =
    if mt.base != nil:
        mt.base.frozen = true
    triggerFlush(mt)

fn computeStallLimit(mt: mem_types.MemTable): int32 =
    if mt.cfg.throttleConfig.stallLimitBytes > 0:
        return mt.cfg.throttleConfig.stallLimitBytes
    return mt.cfg.softLimitBytes

fn computeReleaseTarget(mt: mem_types.MemTable, stallLimit: int32): int32 =
    if mt.cfg.throttleConfig.releaseTargetBytes > 0:
        return mt.cfg.throttleConfig.releaseTargetBytes
    if stallLimit <= 0:
        return 0
    let reduction = max(1, stallLimit div 4)
    return max(0, stallLimit - reduction)

fn reserveBytes(mt: mem_types.MemTable, bytes: int32) =
    if bytes <= 0:
        return
    let projected = mt.bytesUsed + bytes
    if mt.cfg.hardLimitBytes > 0 and projected > mt.cfg.hardLimitBytes:
        raise newException(mem_types.MemError, "memtable capacity exceeded (hard limit)")
    if mt.cfg.resourceManager != nil:
        let ticket = resource.AcquireQuota(mt.cfg.resourceManager, mt.cfg.resourceKind, bytes.int64)
        mt.tickets.add(ticket)
    mt.bytesUsed = projected
    if mt.base != nil:
        mt.base.approxBytes = projected
    if mt.cfg.resourceManager != nil and resource.IsSoftExceeded(mt.cfg.resourceManager, mt.cfg.resourceKind):
        markFrozenForFlush(mt)

fn checkWritable(mt: mem_types.MemTable) =
    if mt.base != nil and mt.base.frozen:
        raise newException(mem_types.MemError, "memtable is frozen and cannot accept new writes")

fn estimateEntryBytes(key: core_types.Key, value: str): int32 =
    return core_types.ToBytes(key).len + value.len + EntryOverhead

fn appendRecord(mt: mem_types.MemTable, key: core_types.Key,
                seq: core_types.SequenceNumber,
                kind: mem_types.MemValueKind,
                value: str) =
    checkWritable(mt)
    verifySequence(mt, seq)
    let sizeBytes = estimateEntryBytes(key, value)
    reserveBytes(mt, sizeBytes)
    mt.records.add(mem_types.MemRecord(key: key, seq: seq, kind: kind, value: value))
    if core_types.ToUint64(seq) >= core_types.ToUint64(mt.lastSeq):
        mt.lastSeq = seq
    if mt.cfg.softLimitBytes > 0 and mt.bytesUsed >= mt.cfg.softLimitBytes:
        markFrozenForFlush(mt)

fn Put(mt: mem_types.MemTable, key: core_types.Key, value: str,
       seq: core_types.SequenceNumber) =
    appendRecord(mt, key, seq, mem_types.MemValueSet, value)

fn Delete(mt: mem_types.MemTable, key: core_types.Key,
          seq: core_types.SequenceNumber) =
    appendRecord(mt, key, seq, mem_types.MemValueDelete, "")

fn Merge(mt: mem_types.MemTable, key: core_types.Key,
         operand: str,
         seq: core_types.SequenceNumber) =
    if not mem_types.HasMerge(mt.cfg):
        raise newException(mem_types.MemError, "merge requested without configured merge operator")
    appendRecord(mt, key, seq, mem_types.MemValueMerge, operand)

fn PrecheckApplyBatch(mt: mem_types.MemTable, entries: openArray[mem_types.ApplyEntry]) =
    if mt == nil:
        raise newException(mem_types.MemError, "memtable is nil")
    checkWritable(mt)
    if entries.len == 0:
        return
    var projected = mt.bytesUsed
    var prevSeq = core_types.ToUint64(mt.lastSeq)
    var reserveDelta: int64 = 0
    for entry in entries:
        let seqValue = core_types.ToUint64(entry.seq)
        if seqValue < prevSeq:
            raise newException(mem_types.MemError,
                "sequence numbers must be monotonically increasing")
        prevSeq = seqValue
        if entry.kind == mem_types.MemValueMerge and not mem_types.HasMerge(mt.cfg):
            raise newException(mem_types.MemError,
                "merge requested without configured merge operator")
        let sizeBytes = estimateEntryBytes(entry.key, entry.value)
        if mt.cfg.hardLimitBytes > 0 and projected + sizeBytes > mt.cfg.hardLimitBytes:
            raise newException(mem_types.MemError, "memtable capacity exceeded (hard limit)")
        projected = projected + sizeBytes
        reserveDelta = reserveDelta + sizeBytes.int64
    if mt.cfg.resourceManager != nil:
        let rm = mt.cfg.resourceManager
        let idx = int32(mt.cfg.resourceKind)
        if not rm.hasQuota[idx]:
            raise newException(mem_types.MemError, "resource quota not configured for memtable kind")
        let quota = rm.quotas[idx]
        if quota.hardLimit > 0 and quota.inUse + reserveDelta > quota.hardLimit:
            raise newException(mem_types.MemError, "memtable capacity exceeded (resource hard limit)")

fn ApplyBatch(mt: mem_types.MemTable, entries: openArray[mem_types.ApplyEntry]) =
    if mt == nil:
        raise newException(mem_types.MemError, "memtable is nil")
    if entries.len == 0:
        return
    PrecheckApplyBatch(mt, entries)
    var totalBytes: int32 = 0
    for entry in entries:
        totalBytes = totalBytes + estimateEntryBytes(entry.key, entry.value)
    reserveBytes(mt, totalBytes)
    for entry in entries:
        mt.records.add(mem_types.MemRecord(
            key: entry.key,
            seq: entry.seq,
            kind: entry.kind,
            value: entry.value
        ))
        if core_types.ToUint64(entry.seq) >= core_types.ToUint64(mt.lastSeq):
            mt.lastSeq = entry.seq
    if mt.cfg.softLimitBytes > 0 and mt.bytesUsed >= mt.cfg.softLimitBytes:
        markFrozenForFlush(mt)

fn AdmitWrite(mt: mem_types.MemTable,
              priority: mem_types.MemWritePriority,
              incomingBytes: int32): int32 =
    if mt == nil or incomingBytes <= 0:
        return 0
    let cfg = mt.cfg.throttleConfig
    let stallLimit = computeStallLimit(mt)
    if not mem_types.ThrottleEnabled(cfg) or stallLimit <= 0:
        if mt.throttleActive:
            let releaseTarget = computeReleaseTarget(mt, max(stallLimit, 0))
            if releaseTarget <= 0 or mt.bytesUsed <= releaseTarget:
                mt.throttleActive = false
                mt.lastThrottleDelayMs = 0
        return 0
    let projected = mt.bytesUsed + incomingBytes
    let releaseTarget = computeReleaseTarget(mt, stallLimit)
    if projected < stallLimit:
        if mt.throttleActive and (releaseTarget <= 0 or projected <= releaseTarget):
            mt.throttleActive = false
            mt.lastThrottleDelayMs = 0
        return 0
    triggerFlush(mt)
    var effective = priority
    if effective == mem_types.MemPriorityDefault:
        effective = mem_types.MemPriorityNormal
    var scaleValue: float64 = 1.0
    if effective == mem_types.MemPriorityLow:
        scaleValue = cfg.priorityScaleLow
    elif effective == mem_types.MemPriorityNormal:
        scaleValue = cfg.priorityScaleNormal
    elif effective == mem_types.MemPriorityHigh:
        scaleValue = cfg.priorityScaleHigh
    if scaleValue <= 0.0:
        scaleValue = 1.0
    let baseDelay = max(1, cfg.baseDelayMs)
    let maxDelay = max(baseDelay, cfg.maxDelayMs)
    let over = projected - stallLimit
    var ratio = over.float / max(1, stallLimit).float
    if ratio > 1.0:
        ratio = 1.0
    let dynamic = int32(ratio * float64(maxDelay - baseDelay) * scaleValue)
    var delay = baseDelay + dynamic
    delay = max(baseDelay, delay)
    delay = min(maxDelay, delay)
    mt.throttleActive = true
    mt.lastThrottleDelayMs = delay
    return delay

fn mergeResolve(mt: mem_types.MemTable, key: core_types.Key,
                base: option.Option[str], operands: seq[str]): option.Option[str] =
    if operands.len == 0:
        return base
    if not mem_types.HasMerge(mt.cfg):
        raise newException(mem_types.MemError, "merge resolution requested without operator")
    var ordered = newSeq[str](operands.len)
    var i: int32 = 0
    let last = operands.len - 1
    while i < operands.len:
        ordered[i] = operands[last - i]
        i = i + 1
    return mt.cfg.mergeOperator(key, base, ordered)

fn Get(mt: mem_types.MemTable,
       key: core_types.Key,
       snapshot: core_types.SequenceNumber): option.Option[str] =
    let snapValue = core_types.ToUint64(snapshot)
    var operands = newSeq[str]()
    var base = option.none(str)
    var seen = false
    if mt == nil:
        return base
    var idx: int32 = mt.records.len - 1
    while idx >= 0:
        let record = mt.records[idx]
        if mt.base != nil and mt.base.comparator != nil:
            if mt.base.comparator(key, record.key) != 0:
                if idx == 0:
                    break
                idx = idx - 1
                continue
        if core_types.ToUint64(record.seq) > snapValue:
            if idx == 0:
                break
            idx = idx - 1
            continue
        seen = true
        if record.kind == mem_types.MemValueSet:
            base = option.some(record.value)
            break
        elif record.kind == mem_types.MemValueDelete:
            base = option.none(str)
            break
        else:
            operands.add(record.value)
        if idx == 0:
            break
        idx = idx - 1
    if not seen:
        return option.none(str)
    if operands.len == 0:
        return base
    return mergeResolve(mt, key, base, operands)

fn GetLatest(mt: mem_types.MemTable, key: core_types.Key): option.Option[str] =
    return Get(mt, key, core_types.ToSequence(uint64(0xFFFFFFFFFFFFFFFF)))

fn Freeze(mt: mem_types.MemTable) =
    if mt.base != nil:
        mt.base.frozen = true

fn ReadyForFlush(mt: mem_types.MemTable): bool =
    if mt.base == nil:
        return false
    return mt.base.frozen

fn NeedsFlush(mt: mem_types.MemTable): bool =
    if mt.cfg.softLimitBytes > 0 and mt.bytesUsed >= mt.cfg.softLimitBytes:
        return true
    if mt.cfg.resourceManager != nil:
        return resource.IsSoftExceeded(mt.cfg.resourceManager, mt.cfg.resourceKind)
    return false

fn Clear(mt: mem_types.MemTable) =
    if mt == nil:
        return
    if mt.cfg.resourceManager != nil:
        for ticket in mt.tickets:
            resource.Release(mt.cfg.resourceManager, ticket)
    mt.tickets.setLen(0)
    mt.records.setLen(0)
    mt.bytesUsed = 0
    if mt.base != nil:
        mt.base.approxBytes = 0
        mt.base.frozen = false
    mt.lastSeq = core_types.ToSequence(0)
    mt.flushScheduled = false
    mt.throttleActive = false
    mt.lastThrottleDelayMs = 0

fn MarkFlushCompleted(mt: mem_types.MemTable) =
    if mt == nil:
        return
    mt.flushScheduled = false
    if mt.base != nil:
        mt.base.frozen = false
    mt.throttleActive = false
    mt.lastThrottleDelayMs = 0
